{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3deca745-0a30-45fc-a912-1d6c2877793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52e2f88-186f-4909-bda6-da7a77a581a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. Write a code to print the data present in the second row of the dataframe, df.\n",
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecdce0-2c13-45d4-9b43-8a361a89da21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8488243-2952-4363-9c46-a01c35ae9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?\n",
    "\n",
    "# loc and iloc are both methods in the pandas library that allow you to select data from a DataFrame based on indices or labels.\n",
    "\n",
    "# loc is primarily label-based, meaning that it is used to select data based on row labels and column names. You can use loc to select rows and columns by passing the row label(s) and column label(s) as arguments. For example, to select the value in row 'A' and column 'B' of a DataFrame df, you would use df.loc['A', 'B'].\n",
    "\n",
    "# iloc, on the other hand, is primarily integer-based, meaning that it is used to select data based on the integer position of the rows and columns. You can use iloc to select rows and columns by passing the row index(es) and column index(es) as arguments. For example, to select the value in the first row and second column of a DataFrame df, you would use df.iloc[0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122aa4a9-045b-458e-8a4c-1c3e75c39372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934fe266-06e1-43ad-8211-d14aba84fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "# Did you observe any difference in both the outputs? If so then explain it.Consider the below code to answer further questions:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1105821-6495-4b25-be6d-fb6355838cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df1.reindex([3,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07de407d-445b-4851-9a27-14775e487b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.343500\n",
       "column_2    0.229118\n",
       "column_3    0.677373\n",
       "column_4    0.382867\n",
       "column_5    0.999552\n",
       "column_6    0.998261\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e9fe4d-5fd1-41fd-aae3-1802febb7772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.028534\n",
       "column_2    0.868340\n",
       "column_3    0.524092\n",
       "column_4    0.441999\n",
       "column_5    0.834611\n",
       "column_6    0.524680\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5e69e6-ed44-448b-bad5-370353426422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see from the output, there is a difference between the output of new_df.loc[2] and new_df.iloc[2].\n",
    "\n",
    "# new_df.loc[2] selects the row with label 2 from the DataFrame new_df. Since the DataFrame was reindexed, the label 2 corresponds to the row that was originally labeled 3 in df1. Thus, the output displays the values for that row.\n",
    "\n",
    "# On the other hand, new_df.iloc[2] selects the row with index position 2 from the DataFrame new_df. Since the DataFrame was reindexed, the row at index position 2 corresponds to the row that was originally at index position 1 in df1. Thus, the output displays the values for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eea52c-27c4-4c94-b7f9-0fb933764955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf33856-6b54-4737-941e-e009968713aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.292838\n",
       "column_2    0.567254\n",
       "column_3    0.511774\n",
       "column_4    0.589855\n",
       "column_5    0.647023\n",
       "column_6    0.609389\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "# (i) mean of each and every column present in the dataframe.\n",
    "# (ii) standard deviation of column, ‘column_2’\n",
    "\n",
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c61a1d6-04bd-48e9-9762-e1f48649ba8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36692250126357523"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['column_2'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d38bba-8b37-47c4-9f5b-bf0d6cf9107d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd1bea1-d786-4d93-8ef1-5e2967dc6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2.\n",
    "# If you are getting errors in executing it then explain why.\n",
    "# [Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]\n",
    "\n",
    "df1.loc['column_2', 1]= \"vishwesh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "116f8eee-2370-4149-a335-c0fec6d57239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672539835124716"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['column_2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d9751-be63-42fb-a3c1-f2b6cb905d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83524e33-ccba-4a08-9384-861edbf6c7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d610e2f3-da6e-4e3f-9007-caf8e41eac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. What do you understand about the windows function in pandas and list the types of windows functions?\n",
    "\n",
    "# In pandas, a window function (also known as a rolling or sliding window) is a function that operates on a specified window of data in a time series or DataFrame. The window moves over the data in a specified direction, such as forward or backward, and calculates a statistic or value for each window.\n",
    "\n",
    "# The different types of window functions available in pandas are:\n",
    "\n",
    "# Rolling: This function creates a rolling window object that can be used to perform calculations on a rolling window of data. The window can be specified using the window size, which can be either a number of periods or a time frequency.\n",
    "\n",
    "# Expanding: This function creates an expanding window object that can be used to perform calculations on an expanding window of data. The window starts from the first period and includes all preceding periods.\n",
    "\n",
    "# Exponentially weighted: This function creates an exponentially weighted moving window object that can be used to perform calculations on a moving window of data. The window size can be specified using the span or the center of mass, which controls the rate at which the weights decrease over time.\n",
    "\n",
    "# Rolling with time-based offsets: This function creates a rolling window object that uses a time-based offset to define the window size. The window can be specified using a time frequency, such as hours, days, or weeks.\n",
    "\n",
    "# Rolling with variable-length windows: This function creates a rolling window object that has a variable-length window size. The window size can be defined based on the values in the data or using a function that calculates the window size.\n",
    "\n",
    "# These window functions can be used to perform various calculations on time series data, such as calculating rolling means, cumulative sums, and exponential moving averages. They are powerful tools for analyzing and visualizing time series data in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fbf65-af5a-470d-b7a5-300f71d6fc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ed9f4c-d640-402c-98ff-fc4998e53b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month:  3\n",
      "Current year:  2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2079/3033766903.py:7: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  current_date = pd.datetime.now()\n"
     ]
    }
   ],
   "source": [
    "# Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "# [Hint: Use pandas.datetime function]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# get the current date and time\n",
    "current_date = pd.datetime.now()\n",
    "\n",
    "# extract the month and year from the current date\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# print the month and year\n",
    "print(\"Current month: \", current_month)\n",
    "print(\"Current year: \", current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d836075-7d71-4e9a-9aeb-31b22d609b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be0583c7-3e1b-42aa-b19e-f92f36320e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2001-06-30\n",
      "Enter the second date (YYYY-MM-DD):  2023-03-23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between 2001-06-30 and 2023-03-23 is 7936 days, 0 hours, and 0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# prompt the user to enter the dates\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# convert the dates to datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# calculate the difference between the dates\n",
    "diff = date2 - date1\n",
    "\n",
    "# extract the number of days, hours, and minutes from the difference\n",
    "days = diff.days\n",
    "hours = diff.seconds // 3600\n",
    "minutes = (diff.seconds % 3600) // 60\n",
    "\n",
    "# display the result\n",
    "print(f\"The difference between {date1.date()} and {date2.date()} is {days} days, {hours} hours, and {minutes} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce58cb-1668-4dc5-b9e6-11be4e77ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79d95232-dcb7-4ded-b7ff-8adc62445dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path:  https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
      "Enter the column name:  Pclass\n",
      "Enter the category order (comma-separated):  Age\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived Pclass  \\\n",
      "0              1         0    NaN   \n",
      "1              2         1    NaN   \n",
      "2              3         1    NaN   \n",
      "3              4         1    NaN   \n",
      "4              5         0    NaN   \n",
      "..           ...       ...    ...   \n",
      "886          887         0    NaN   \n",
      "887          888         1    NaN   \n",
      "888          889         0    NaN   \n",
      "889          890         1    NaN   \n",
      "890          891         0    NaN   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# prompt the user to enter the file path, column name, and category order\n",
    "file_path = input(\"Enter the file path: \")\n",
    "col_name = input(\"Enter the column name: \")\n",
    "categories = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# convert the specified column to categorical data type\n",
    "df[col_name] = pd.Categorical(df[col_name], categories=categories, ordered=True)\n",
    "\n",
    "# display the sorted data\n",
    "print(df.sort_values(by=[col_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c327cf-b5e0-44b3-b306-ba9f2e88478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1eb65f-0147-4ad3-8696-f66f9d70f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path:  https://www.mathsisfun.com/data/pie-charts.html\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 9, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the file path: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# read the CSV file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# create a pivot table to group the data by product category and year\u001b[39;00m\n\u001b[1;32m     13\u001b[0m pivot \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(df, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth_number\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_units\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_profit\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 9, saw 4\n"
     ]
    }
   ],
   "source": [
    "# Q10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path: \")\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# create a pivot table to group the data by product category and year\n",
    "pivot = pd.pivot_table(df, values='month_number', index='total_units', columns='total_profit', aggfunc='sum')\n",
    "\n",
    "# plot the stacked bar chart\n",
    "pivot.plot(kind='bar', stacked=True)\n",
    "\n",
    "# set the chart title and axis labels\n",
    "plt.title('Sales by Product Category')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6953dee-763c-4370-bce5-34fdd7523063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26bf7c59-5549-4889-9b03-59e7f3022bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and displays the results in a table.\n",
    "# The program should do the following:\n",
    "# Prompt the user to enter the file path of the CSV file containing the student data\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "# Calculate the mean, median, and mode of the test scores using Pandas tools\n",
    "# Display the mean, median, and mode in a table.\n",
    "# ## Assume the CSV file contains the following columnsM\n",
    "# Student ID: The ID of the studentR\n",
    "# Test Score: The score of the student's test.\n",
    "# Example usage of the program:\n",
    "# Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "# +-----------+--------+\n",
    "# | Statistic | Value |\n",
    "# +-----------+--------+\n",
    "# | Mean | 79.6 |\n",
    "# | Median | 82 |\n",
    "# | Mode | 85, 90 |\n",
    "# +-----------+--------+\n",
    "# Assume that the CSV file student_data.csv contains the following data:\n",
    "# Student ID,Test Score\n",
    "# 1,85\n",
    "# 2,90\n",
    "# 3,80\n",
    "# 4,75\n",
    "# 5,85\n",
    "# 6,82\n",
    "# 7,78\n",
    "# 8,85\n",
    "# 9,90\n",
    "# 10,85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a527b43-3b6c-4d63-b1c6-343396ab8c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# calculate the mean, median, and mode of the test scores\n",
    "mean = df['gre'].mean()\n",
    "median = df['gre'].median()\n",
    "mode = df['gre'].mode().tolist()\n",
    "\n",
    "# display results in table format\n",
    "print('+-----------+--------+')\n",
    "print('| Statistic | Value  |')\n",
    "print('+-----------+--------+')\n",
    "print(f'| Mean      | {mean:.1f}  |')\n",
    "print(f'| Median    | {median}  |')\n",
    "print(f'| Mode      | {mode}  |')\n",
    "print('+-----------+--------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1024c2-12dc-41d2-8fab-ecc4139a40f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
